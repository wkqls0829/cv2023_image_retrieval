wandb: Appending key for api.wandb.ai to your netrc file: /home/kjb/.netrc
wandb: Currently logged in as: jabin. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.1
wandb: Run data is saved locally in /home/kjb/cv/image_retrieval/Training_Results/wandb/run-20231208_175000-mx0s8f20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cub200lt_if0.5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jabin/DML_Project
wandb: üöÄ View run at https://wandb.ai/jabin/DML_Project/runs/mx0s8f20
spliting test data into [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10] number of datasets
spliting train data into [50, 49, 49, 49, 44, 41, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 45, 46, 46, 46, 46, 46, 46, 45, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44, 43, 43, 43, 43, 43, 43, 43, 42, 42, 42, 42, 42, 42, 42, 41, 41, 41, 41, 41, 41, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 39, 38, 38, 38, 38, 38, 38, 38, 37, 37, 37, 37, 37, 37, 37, 37, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35, 35, 35, 35, 35, 34, 34, 34, 34, 34, 34, 34, 34, 33, 33, 33, 33, 33, 33, 33, 33, 33, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25] number of datasets

Dataset Setup:
Using Train-Val Split: False
#Classes: Train (200) | Val (X) | Test (200)

Dataset:	 CUB200
Objective:	 MARGIN
Batchminer:	 distance
Backbone:	 RESNET50_FROZEN_NORMALIZE (#weights: 23770304)

-----

Running with learning rates 1e-05 | 0.0005...
Epoch 0 Training...:   0%|          | 0/63 [00:00<?, ?it/s]Epoch 0 Training...:   2%|‚ñè         | 1/63 [00:15<16:24, 15.87s/it]Epoch 0 Training...:   3%|‚ñé         | 2/63 [00:16<06:55,  6.82s/it]Epoch 0 Training...:   5%|‚ñç         | 3/63 [00:16<03:55,  3.92s/it]Epoch 0 Training...:   6%|‚ñã         | 4/63 [00:17<02:31,  2.56s/it]Epoch 0 Training...:   8%|‚ñä         | 5/63 [00:17<01:45,  1.82s/it]Epoch 0 Training...:  10%|‚ñâ         | 6/63 [00:18<01:17,  1.36s/it]Epoch 0 Training...:  11%|‚ñà         | 7/63 [00:23<02:22,  2.54s/it]Epoch 0 Training...:  13%|‚ñà‚ñé        | 8/63 [00:23<01:43,  1.88s/it]Epoch 0 Training...:  14%|‚ñà‚ñç        | 9/63 [00:24<01:17,  1.43s/it]Epoch 0 Training...:  16%|‚ñà‚ñå        | 10/63 [00:24<00:59,  1.12s/it]Epoch 0 Training...:  17%|‚ñà‚ñã        | 11/63 [00:25<00:47,  1.09it/s]Epoch 0 Training...:  19%|‚ñà‚ñâ        | 12/63 [00:25<00:39,  1.30it/s]Epoch 0 Training...:  21%|‚ñà‚ñà        | 13/63 [00:32<02:08,  2.56s/it]Epoch 0 Training...:  22%|‚ñà‚ñà‚ñè       | 14/63 [00:32<01:34,  1.92s/it]Epoch 0 Training...:  24%|‚ñà‚ñà‚ñç       | 15/63 [00:33<01:10,  1.48s/it]Epoch 0 Training...:  25%|‚ñà‚ñà‚ñå       | 16/63 [00:33<00:55,  1.17s/it]Epoch 0 Training...:  27%|‚ñà‚ñà‚ñã       | 17/63 [00:33<00:44,  1.04it/s]Epoch 0 Training...:  29%|‚ñà‚ñà‚ñä       | 18/63 [00:34<00:36,  1.24it/s]Epoch 0 Training...:  30%|‚ñà‚ñà‚ñà       | 19/63 [00:41<01:59,  2.72s/it]Epoch 0 Training...:  32%|‚ñà‚ñà‚ñà‚ñè      | 20/63 [00:42<01:27,  2.05s/it]Epoch 0 Training...:  33%|‚ñà‚ñà‚ñà‚ñé      | 21/63 [00:42<01:06,  1.57s/it]Epoch 0 Training...:  35%|‚ñà‚ñà‚ñà‚ñç      | 22/63 [00:43<00:51,  1.24s/it]Epoch 0 Training...:  37%|‚ñà‚ñà‚ñà‚ñã      | 23/63 [00:43<00:40,  1.01s/it]Epoch 0 Training...:  38%|‚ñà‚ñà‚ñà‚ñä      | 24/63 [00:43<00:32,  1.19it/s]Epoch 0 Training...:  40%|‚ñà‚ñà‚ñà‚ñâ      | 25/63 [00:50<01:35,  2.51s/it]Epoch 0 Training...:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 26/63 [00:50<01:10,  1.91s/it]Epoch 0 Training...:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 27/63 [00:51<00:53,  1.49s/it]Epoch 0 Training...:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 28/63 [00:51<00:41,  1.18s/it]Epoch 0 Training...:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 29/63 [00:52<00:32,  1.04it/s]Epoch 0 Training...:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 30/63 [00:52<00:26,  1.24it/s]Epoch 0 Training...:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 31/63 [00:58<01:09,  2.17s/it]Epoch 0 Training...:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 32/63 [00:58<00:51,  1.65s/it]Epoch 0 Training...:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 33/63 [00:58<00:38,  1.30s/it]Epoch 0 Training...:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 34/63 [00:59<00:30,  1.05s/it]Epoch 0 Training...:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 35/63 [00:59<00:24,  1.13it/s]Epoch 0 Training...:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/63 [01:00<00:20,  1.30it/s]